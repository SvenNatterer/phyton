{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9f6134d8-75ae-4e5c-a590-96e98cc80584",
      "metadata": {},
      "source": [
        "# Exercises for Introduction to Python for Data Science\n",
        "\n",
        "Week 10 - scikit-learn\n",
        "\n",
        "Matthias Feurer and Andreas Bender  \n",
        "2025-07-07"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8b14191-20f8-40e7-918f-cbde7743edb2",
      "metadata": {},
      "source": [
        "# Setup\n",
        "\n",
        "Check that you have at least **scikit‑learn ≥ 1.4** and\n",
        "**pandas ≥ 2.0**.\n",
        "\n",
        "    import sklearn, pandas as pd, numpy as np\n",
        "    print(\"scikit‑learn\", sklearn.__version__)\n",
        "    print(\"pandas\", pd.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "982f2914",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "scikit‑learn 1.6.1\n",
            "pandas 2.2.3\n"
          ]
        }
      ],
      "source": [
        "    import sklearn, pandas as pd, numpy as np\n",
        "    print(\"scikit‑learn\", sklearn.__version__)\n",
        "    print(\"pandas\", pd.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa2b6ef8-de98-409c-ad5e-1f85496c2d08",
      "metadata": {},
      "source": [
        "# Exercise 1: Download an appropriate dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76661c02-37b0-4e03-bfb9-eef6ca41287c",
      "metadata": {},
      "source": [
        "*Download a tabular regression dataset that already contains categorical\n",
        "columns **and** missing values.* Two popular options:\n",
        "\n",
        "1.  **Ames Housing** — numeric + categorical + some NaNs.\n",
        "\n",
        "2.  **Mercedes‑Benz Greener Manufacturing** (*OpenML ID = 42165*) if you\n",
        "    prefer a smaller data set.\n",
        "\n",
        "Store **features** `X` and **target** `y` as Pandas objects—no NumPy\n",
        "arrays outside the pipeline!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ee57255b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>Alley</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>...</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>PoolQC</th>\n",
              "      <th>Fence</th>\n",
              "      <th>MiscFeature</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>65.0</td>\n",
              "      <td>8450</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9600</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>68.0</td>\n",
              "      <td>11250</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>70</td>\n",
              "      <td>RL</td>\n",
              "      <td>60.0</td>\n",
              "      <td>9550</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Abnorml</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>84.0</td>\n",
              "      <td>14260</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 80 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
              "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
              "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
              "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
              "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
              "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
              "\n",
              "  LandContour Utilities  ... ScreenPorch PoolArea PoolQC Fence MiscFeature  \\\n",
              "0         Lvl    AllPub  ...           0        0    NaN   NaN         NaN   \n",
              "1         Lvl    AllPub  ...           0        0    NaN   NaN         NaN   \n",
              "2         Lvl    AllPub  ...           0        0    NaN   NaN         NaN   \n",
              "3         Lvl    AllPub  ...           0        0    NaN   NaN         NaN   \n",
              "4         Lvl    AllPub  ...           0        0    NaN   NaN         NaN   \n",
              "\n",
              "  MiscVal MoSold  YrSold  SaleType  SaleCondition  \n",
              "0       0      2    2008        WD         Normal  \n",
              "1       0      5    2007        WD         Normal  \n",
              "2       0      9    2008        WD         Normal  \n",
              "3       0      2    2006        WD        Abnorml  \n",
              "4       0     12    2008        WD         Normal  \n",
              "\n",
              "[5 rows x 80 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "\n",
        "X, y = fetch_openml(\n",
        "    name=\"house_prices\",\n",
        "    version=\"active\",\n",
        "    as_frame=True,\n",
        "    return_X_y=True,\n",
        "    parser=\"pandas\"          # parser=\"pandas\" ist empfohlen, um Warnungen zu vermeiden\n",
        ")\n",
        "X.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ed183a2-b687-4b8e-a5aa-82d3194ead0c",
      "metadata": {},
      "source": [
        "# Exercise 2: Pipeline\n",
        "\n",
        "Your end‑to‑end pipeline must:\n",
        "\n",
        "1.  **Impute missing values**\n",
        "\n",
        "    -   Numeric → Impute using the mean.\n",
        "    -   Categorical → Create a new category that indicates missing data.\n",
        "\n",
        "2.  **Encode categoricals** with\n",
        "    `OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)`.\n",
        "\n",
        "3.  **Scale numerical features** so that they have zero mean and unit\n",
        "    variance.\n",
        "\n",
        "4.  **Parallel feature branches**: create three parallel feature\n",
        "    branches where the data is processed in differen manners:\n",
        "\n",
        "    -   **Branch A** — use only simple preprocessing (steps 1-3).\n",
        "    -   **Branch B** — apply principal component analysis.\n",
        "    -   **Branch C** — apply k-means clustering and add new features\n",
        "        that measure the distance to all cluster centers.\n",
        "\n",
        "5.  **Regressor**: Use ridge regression and tune the regularization\n",
        "    hyperparameter.\n",
        "\n",
        "6.  **Target scaling**: scale the target so it automatically has zero\n",
        "    mean and unit variance.\n",
        "\n",
        "Everything must be wired up in a single `Pipeline` so that a call to\n",
        "**`fit()`** triggers *all* preprocessing.\n",
        "\n",
        "HINTS: \\* Call `set_output(transform=\"pandas\")` **once** to make every\n",
        "transformer emit data frames → keeps column names alive. \\* You need to\n",
        "use `ColumnTransformer`, `Pipeline` and `FeatureUnion` in order to solve\n",
        "this exercise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "5b0ba791",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1460, 80)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "beedfc01",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bestes alpha: 100.0\n",
            "Bestes CV-MSE: 1026808441.8150259\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn import set_config\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.linear_model import Ridge, RidgeCV\n",
        "from sklearn.compose import TransformedTargetRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# ─── 0) Global: alle Transformer geben pandas.DataFrames zurück ───\n",
        "set_config(transform_output=\"pandas\")\n",
        "\n",
        "\n",
        "# alle numerischen Spalten-Namen\n",
        "numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "# alle “object”-Spalten (Strings) – \n",
        "# oft willst Du hier auch 'category' mit aufnehmen:\n",
        "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "# ─── 2) Basistransformer: Imputation, Encoding, Scaling ───\n",
        "numeric_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler',   StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('onehot',  OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', numeric_pipeline,     numeric_cols),\n",
        "    ('cat', categorical_pipeline, categorical_cols)\n",
        "], remainder='drop')\n",
        "\n",
        "# ─── 3) Parallele Feature-Branches ───\n",
        "# Branch A: nur Basis-Preprocessing\n",
        "branch_A = preprocessor\n",
        "\n",
        "# Branch B: PCA auf die vorverarbeiteten Features\n",
        "branch_B = Pipeline([\n",
        "    ('pre', preprocessor),\n",
        "    ('pca', PCA())         # z.B. 5 Hauptkomponenten\n",
        "])\n",
        "\n",
        "# Branch C: K-Means und Distanzen zu Clustern\n",
        "branch_C = Pipeline([\n",
        "    ('pre', preprocessor),\n",
        "    ('kmeans', KMeans(random_state=42))  # z.B. 4 Cluster\n",
        "    # KMeans.fit_transform liefert direkt die Distanzen zu den Cluster-Zentren\n",
        "])\n",
        "\n",
        "# FeatureUnion aller drei Branches\n",
        "features = FeatureUnion([\n",
        "    ('A', branch_A),\n",
        "    ('B', branch_B),\n",
        "    ('C', branch_C)\n",
        "], n_jobs=-1)\n",
        "\n",
        "\n",
        "alphas = np.logspace(-6, 6, 25)\n",
        "     \n",
        "\n",
        "# ─── 4) Regressor mit Target-Scaling ───\n",
        "regressor = TransformedTargetRegressor(\n",
        "    regressor=Ridge(),\n",
        "    transformer=StandardScaler()\n",
        ")\n",
        "\n",
        "param_grid = {\n",
        "    'reg__regressor__alpha': np.logspace(-6, 6, 25)\n",
        "}\n",
        "\n",
        "# ─── 5) Gesamte Pipeline ───\n",
        "pipe = Pipeline([\n",
        "    ('features', features),\n",
        "    ('reg',      regressor)\n",
        "])\n",
        "\n",
        "grid = GridSearchCV(\n",
        "    estimator=pipe,\n",
        "    param_grid=param_grid,\n",
        "    scoring=\"neg_mean_squared_error\",\n",
        "    cv=5\n",
        ")\n",
        "\n",
        "grid.fit(X, y)\n",
        "\n",
        "print(\"Bestes alpha:\", grid.best_params_['reg__regressor__alpha'])\n",
        "print(\"Bestes CV-MSE:\", -grid.best_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ec88cb5-92d4-4178-9a57-9d8a4f53b874",
      "metadata": {},
      "source": [
        "# Exercise 3: Cross-Validation\n",
        "\n",
        "-   Use **10‑fold cross‑validation** (you can start with 2-fold\n",
        "    cross-validation for development):\n",
        "-   Compare against a *baseline* that simply imputes + encodes and uses\n",
        "    the same linear models (no PCA/Clustering). Did the extra branches\n",
        "    help?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5481714f-aab2-47f7-9973-11d481b8261f",
      "metadata": {},
      "source": [
        "Using all three pre-processing strategies in parallel results in a\n",
        "slight performance improvement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "47965040",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/svennatterer/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bestes CV-MSE: 1036199874.5081649\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/svennatterer/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bestes CV-MSE: 999869078.0793294\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn import set_config\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.linear_model import Ridge, RidgeCV\n",
        "from sklearn.compose import TransformedTargetRegressor\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold\n",
        "\n",
        "# ─── 0) Global: alle Transformer geben pandas.DataFrames zurück ───\n",
        "set_config(transform_output=\"pandas\")\n",
        "\n",
        "\n",
        "# alle numerischen Spalten-Namen\n",
        "numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "# alle “object”-Spalten (Strings) – \n",
        "# oft willst Du hier auch 'category' mit aufnehmen:\n",
        "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "# ─── 2) Basistransformer: Imputation, Encoding, Scaling ───\n",
        "numeric_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler',   StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('onehot',  OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', numeric_pipeline,     numeric_cols),\n",
        "    ('cat', categorical_pipeline, categorical_cols)\n",
        "], remainder='drop')\n",
        "\n",
        "# ─── 3) Parallele Feature-Branches ───\n",
        "# Branch A: nur Basis-Preprocessing\n",
        "branch_A = preprocessor\n",
        "\n",
        "# Branch B: PCA auf die vorverarbeiteten Features\n",
        "branch_B = Pipeline([\n",
        "    ('pre', preprocessor),\n",
        "    ('pca', PCA())         # z.B. 5 Hauptkomponenten\n",
        "])\n",
        "\n",
        "# Branch C: K-Means und Distanzen zu Clustern\n",
        "branch_C = Pipeline([\n",
        "    ('pre', preprocessor),\n",
        "    ('kmeans', KMeans(random_state=42))  # z.B. 4 Cluster\n",
        "    # KMeans.fit_transform liefert direkt die Distanzen zu den Cluster-Zentren\n",
        "])\n",
        "\n",
        "# FeatureUnion aller drei Branches\n",
        "features = FeatureUnion([\n",
        "    ('A', branch_A),\n",
        "    ('B', branch_B),\n",
        "    ('C', branch_C)\n",
        "], n_jobs=-1)\n",
        "\n",
        "\n",
        "alphas = np.logspace(-6, 6, 25)\n",
        "     \n",
        "\n",
        "# ─── 4) Regressor mit Target-Scaling ───\n",
        "regressor = TransformedTargetRegressor(\n",
        "    regressor=Ridge(),\n",
        "    transformer=StandardScaler()\n",
        ")\n",
        "\n",
        "param_grid = {\n",
        "    'reg__regressor__alpha': np.logspace(-6, 6, 25)\n",
        "}\n",
        "\n",
        "# ─── 5) Gesamte Pipeline ───\n",
        "pipe = Pipeline([\n",
        "    ('features', features),\n",
        "    ('reg',      regressor)\n",
        "])\n",
        "\n",
        "grid = GridSearchCV(\n",
        "    estimator=pipe,\n",
        "    param_grid=param_grid,\n",
        "    scoring=\"neg_mean_squared_error\",\n",
        "    cv=5\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "cv = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
        "MSE = cross_val_score(grid, X, y, cv = cv, scoring=\"neg_mean_squared_error\")\n",
        "\n",
        "print(\"Bestes CV-MSE:\", np.mean(-MSE))\n",
        "\n",
        "\n",
        "pipe2 = Pipeline([\n",
        "    ('pre', preprocessor),\n",
        "    ('reg',      regressor)\n",
        "])\n",
        "\n",
        "grid2 = GridSearchCV(\n",
        "    estimator=pipe2,\n",
        "    param_grid=param_grid,\n",
        "    scoring=\"neg_mean_squared_error\",\n",
        "    cv=5\n",
        ")\n",
        "\n",
        "\n",
        "cv = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
        "MSE = cross_val_score(grid2, X, y, cv = cv, scoring=\"neg_mean_squared_error\")\n",
        "\n",
        "print(\"Bestes CV-MSE:\", np.mean(-MSE))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5a97f2c-5b04-4887-ba61-dc2efe4f8131",
      "metadata": {},
      "source": [
        "# Exercise 4: Bonus tasks\n",
        "\n",
        "-   Swap the linear model for `HistGradientBoostingRegressor` and\n",
        "    compare.\n",
        "-   Swap the linear model for `DecisionTreeRegressor`, compare, and plot\n",
        "    the decision tree.\n",
        "-   Run **nested CV** with `RandomizeSearchCV` tuning `n_clusters` and\n",
        "    `n_components`.\n",
        "-   Persit and re-load the model using `joblib.dump` and `joblib.load`."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
